{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"xgboost\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('../../data/player_game_statistics.csv')"
   ],
   "id": "3a89f4fca19fa4d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Inspect the target column\n",
    "print(df['player_level'].value_counts())"
   ],
   "id": "57bf96d504b852b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "numerical_columns = df.select_dtypes(include=np.number).columns\n",
    "df[numerical_columns] = imputer.fit_transform(df[numerical_columns])\n",
    "# df = df.drop(columns=['player_id', 'game_id'])\n",
    "\n",
    "# Encode categorical columns\n",
    "categorical_columns = ['country', 'gender', 'game_name']\n",
    "df = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "df['churned'] = label_encoder.fit_transform(df['churned'])  # Convert churned to binary\n",
    "df['player_level'] = label_encoder.fit_transform(df['player_level'])"
   ],
   "id": "c6b046bda3c8c9e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Split the dataset\n",
    "X = df.drop(columns=['player_level','game_id', 'player_id', 'username', 'last_played'])  # Remove non-informative columns\n",
    "y = df['player_level']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ],
   "id": "2909b9cb417ae5cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "id": "147764452ec01f63",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize models\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "svm_clf = SVC(probability=True, random_state=42)\n"
   ],
   "id": "bf6a0f86681a6e8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train and evaluate each model\n",
    "models = {\n",
    "    \"Logistic Regression\": log_reg,\n",
    "    \"Random Forest\": rf_clf,\n",
    "    \"Gradient Boosting\": gb_clf,\n",
    "    \"SVM\": svm_clf\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Performance of {name}:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ],
   "id": "2faf1ac01a5460a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Collecting all models' results\n",
    "models_list = ['Logistic Regression', 'GBoost', 'SVM', 'Random Forest', 'Voting Classifier']\n",
    "accuracies = [\n",
    "    0.88, 0.95, 0.88, 0.95, 0.94\n",
    "]"
   ],
   "id": "8f9c8e7e6ee3bbf7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Collecting all models' results\n",
    "# models_list = ['Logistic Regression', 'GBoost', 'SVM', 'Random Forest', 'Voting Classifier']\n",
    "# accuracies = [\n",
    "#     accuracy_score(y_test, log_reg_pred),\n",
    "#     accuracy_score(y_test, xgb_pred),\n",
    "#     accuracy_score(y_test, svm_pred),\n",
    "#     accuracy_score(y_test, rf_pred),\n",
    "#     accuracy_score(y_test, voting_pred)\n",
    "# ]"
   ],
   "id": "c75ddec6b7048a37",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plotting the comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models_list, accuracies, color=['blue', 'orange', 'green', 'red', 'purple'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Comparison')\n",
    "plt.ylim(0.6, 1.0)  # Adjust as necessary\n",
    "plt.xticks(rotation=15)\n",
    "plt.show()"
   ],
   "id": "1d1be06a4f6ad086",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Ensemble Model (Voting Classifier)\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('log_reg', log_reg),\n",
    "        ('rf', rf_clf),\n",
    "        ('gb', gb_clf),\n",
    "        ('svm', svm_clf)\n",
    "    ],\n",
    "    voting='soft'  # Soft voting uses predicted probabilities\n",
    ")\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred_ensemble = voting_clf.predict(X_test)"
   ],
   "id": "97b206fa4ab27a7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c112576273b760bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluate ensemble model\n",
    "print(\"Performance of Ensemble Model (Voting Classifier):\")\n",
    "print(classification_report(y_test, y_pred_ensemble))"
   ],
   "id": "a7d9aee609fe1436",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Identify the best-performing model\n",
    "ensemble_accuracy = accuracy_score(y_test, y_pred_ensemble)\n",
    "print(f\"Ensemble Model Accuracy: {ensemble_accuracy:.2f}\")"
   ],
   "id": "3479ecb2f2758816",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Model Testing on new data",
   "id": "bed6388e1d85855a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fb93b75a39974ca1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
