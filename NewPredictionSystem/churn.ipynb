{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-17T19:50:18.545315Z",
     "start_time": "2024-12-17T19:50:16.912939Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pickle"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T19:50:18.608792Z",
     "start_time": "2024-12-17T19:50:18.577135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "df = pd.read_csv('player_game_statistics.csv')"
   ],
   "id": "1f876f1f90f0e05d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T19:50:18.670364Z",
     "start_time": "2024-12-17T19:50:18.615133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Simple feature preparation\n",
    "# Encode categorical variables\n",
    "le_gender = LabelEncoder()\n",
    "le_country = LabelEncoder()\n",
    "df['gender_encoded'] = le_gender.fit_transform(df['gender'])\n",
    "df['country_encoded'] = le_gender.fit_transform(df['country'])\n",
    "\n",
    "# Convert last_played to datetime and calculate days since last played\n",
    "df['last_played'] = pd.to_datetime(df['last_played'])\n",
    "df['days_since_last_play'] = (pd.Timestamp.now() - df['last_played']).dt.days\n",
    "\n",
    "# Define churn (player is considered churned if they haven't played in 30 days and have below average win ratio)\n",
    "avg_win_ratio = df['win_ratio'].mean()\n",
    "df['churned'] = ((df['days_since_last_play'] > 30) & (df['win_ratio'] < avg_win_ratio)).astype(int)\n",
    "\n",
    "# Select features\n",
    "features = [\n",
    "    'total_games_played',\n",
    "    'total_wins',\n",
    "    'total_losses',\n",
    "    'total_moves',\n",
    "    'total_time_played_minutes',\n",
    "    'win_ratio',\n",
    "    'rating',\n",
    "    'age',\n",
    "    'gender_encoded',\n",
    "    'country_encoded',\n",
    "    'days_since_last_play'\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df['churned']\n"
   ],
   "id": "d27ac4471a82495b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T19:50:19.194966Z",
     "start_time": "2024-12-17T19:50:19.181280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ],
   "id": "1d48c7106f90e31b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T19:50:19.289069Z",
     "start_time": "2024-12-17T19:50:19.264987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ],
   "id": "158f0af52a56b742",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T19:50:19.350333Z",
     "start_time": "2024-12-17T19:50:19.338860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42),\n",
    "    'SVM': SVC(random_state=42, probability=True)  # Enable probability estimates for SVM\n",
    "}\n"
   ],
   "id": "45b0c0c30a8fc39f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T19:50:19.741613Z",
     "start_time": "2024-12-17T19:50:19.384172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dictionary to store model performances\n",
    "model_performances = {}\n",
    "\n",
    "# Train and evaluate models\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    model_performances[name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'report': report\n",
    "    }\n",
    "\n",
    "    print(f\"\\nResults for {name}:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n"
   ],
   "id": "d078a1d02a53b3c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Random Forest...\n",
      "\n",
      "Results for Random Forest:\n",
      "Accuracy: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       168\n",
      "           1       1.00      1.00      1.00        32\n",
      "\n",
      "    accuracy                           1.00       200\n",
      "   macro avg       1.00      1.00      1.00       200\n",
      "weighted avg       1.00      1.00      1.00       200\n",
      "\n",
      "\n",
      "Training Logistic Regression...\n",
      "\n",
      "Results for Logistic Regression:\n",
      "Accuracy: 0.8400\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91       168\n",
      "           1       0.50      0.38      0.43        32\n",
      "\n",
      "    accuracy                           0.84       200\n",
      "   macro avg       0.69      0.65      0.67       200\n",
      "weighted avg       0.82      0.84      0.83       200\n",
      "\n",
      "\n",
      "Training XGBoost...\n",
      "\n",
      "Results for XGBoost:\n",
      "Accuracy: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       168\n",
      "           1       1.00      1.00      1.00        32\n",
      "\n",
      "    accuracy                           1.00       200\n",
      "   macro avg       1.00      1.00      1.00       200\n",
      "weighted avg       1.00      1.00      1.00       200\n",
      "\n",
      "\n",
      "Training SVM...\n",
      "\n",
      "Results for SVM:\n",
      "Accuracy: 0.9300\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       168\n",
      "           1       0.91      0.62      0.74        32\n",
      "\n",
      "    accuracy                           0.93       200\n",
      "   macro avg       0.92      0.81      0.85       200\n",
      "weighted avg       0.93      0.93      0.92       200\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T19:50:19.819743Z",
     "start_time": "2024-12-17T19:50:19.791418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Select the best model based on accuracy\n",
    "best_model_name = max(model_performances.items(), key=lambda x: x[1]['accuracy'])[0]\n",
    "best_model = model_performances[best_model_name]['model']\n",
    "\n",
    "print(f\"\\nBest performing model: {best_model_name}\")\n",
    "print(f\"Best Accuracy: {model_performances[best_model_name]['accuracy']:.4f}\")\n",
    "print(\"\\nDetailed Classification Report for Best Model:\")\n",
    "print(classification_report(y_test, best_model.predict(X_test_scaled)))\n"
   ],
   "id": "e0c1046cffb1f59e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best performing model: Random Forest\n",
      "Best Accuracy: 1.0000\n",
      "\n",
      "Detailed Classification Report for Best Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       168\n",
      "           1       1.00      1.00      1.00        32\n",
      "\n",
      "    accuracy                           1.00       200\n",
      "   macro avg       1.00      1.00      1.00       200\n",
      "weighted avg       1.00      1.00      1.00       200\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T19:50:19.926468Z",
     "start_time": "2024-12-17T19:50:19.900274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save best model, scaler, and encoders\n",
    "with open('churn_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "with open('churn_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "with open('gender_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(le_gender, f)\n",
    "\n",
    "with open('country_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(le_country, f)\n"
   ],
   "id": "f2ecd139b1ec57fe",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T19:50:19.988259Z",
     "start_time": "2024-12-17T19:50:19.960120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print feature importances if the best model supports it\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    print(\"\\nFeature importances:\")\n",
    "    for feat, imp in zip(features, best_model.feature_importances_):\n",
    "        print(f\"{feat}: {imp:.4f}\")\n",
    "elif hasattr(best_model, 'coef_'):\n",
    "    print(\"\\nFeature coefficients:\")\n",
    "    for feat, coef in zip(features, best_model.coef_[0]):\n",
    "        print(f\"{feat}: {coef:.4f}\")\n"
   ],
   "id": "39a1fec7271fc0b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature importances:\n",
      "total_games_played: 0.0344\n",
      "total_wins: 0.0532\n",
      "total_losses: 0.0489\n",
      "total_moves: 0.0371\n",
      "total_time_played_minutes: 0.0420\n",
      "win_ratio: 0.2443\n",
      "rating: 0.0377\n",
      "age: 0.0177\n",
      "gender_encoded: 0.0047\n",
      "country_encoded: 0.0135\n",
      "days_since_last_play: 0.4665\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
